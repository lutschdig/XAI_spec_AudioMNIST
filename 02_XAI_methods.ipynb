{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02_XAI_methods.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMH0tH2AtTaSKsqUBswU0eG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1esEfwEt8klm"},"source":["# General"]},{"cell_type":"markdown","metadata":{"id":"E9vNG2yd8sSP"},"source":["## Mount Google Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l67xTDQQ8mkn","executionInfo":{"status":"ok","timestamp":1631178216081,"user_tz":-120,"elapsed":20344,"user":{"displayName":"Philipp Rössler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08136704935029710025"}},"outputId":"c139acfb-8c14-4f67-efd7-a5a78ae219db"},"source":["from google.colab import drive #mount Google Drive\n","drive.mount('/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"markdown","metadata":{"id":"eCBm5OZP8uyk"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"wQfs_2iT8vvH","executionInfo":{"status":"ok","timestamp":1631178219274,"user_tz":-120,"elapsed":3198,"user":{"displayName":"Philipp Rössler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08136704935029710025"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Model, load_model\n","import os\n","import sys\n","import logging\n","import time\n","import h5py\n","import math\n","\n","import json\n","import scipy.io.wavfile as wavf\n","from sklearn.preprocessing import minmax_scale\n","from tensorflow import keras\n","from IPython.display import Image, display\n","import matplotlib.cm as cm\n","from PIL import ImageOps\n","from keras.preprocessing.image import img_to_array,array_to_img"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"15mcpt278wOM"},"source":["## Set Paths"]},{"cell_type":"code","metadata":{"id":"tdSMouMz978D","executionInfo":{"status":"ok","timestamp":1631178219275,"user_tz":-120,"elapsed":4,"user":{"displayName":"Philipp Rössler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08136704935029710025"}}},"source":["# set root dir: the path to the github repo folder \"XAI_spec_TSC\" in your google drive\n","root_dir = '/gdrive/My Drive/XAI_spec_AudioMNIST/'\n","\n","paths = {\n","    'root': root_dir,\n","    'dataset': os.path.join(root_dir,'AudioMNIST-master'),\n","    'data': os.path.join(root_dir,'AudioMNIST-master/data'),\n","    'meta': os.path.join(root_dir,'AudioMNIST-master/data/audioMNIST_meta.txt'),\n","    'spectrograms': os.path.join(root_dir,'spectrograms'),\n","    'splits': os.path.join(root_dir,'splits'),\n","    'results': os.path.join(root_dir, 'results'),\n","    'models': os.path.join(root_dir, 'results/models'),\n","    'history': os.path.join(root_dir, 'results/history'),\n","    'evaluation': os.path.join(root_dir, 'results/evaluation'),\n","    'xai': os.path.join(root_dir, 'results/xai'),\n","    'plots': os.path.join(root_dir, 'results/plots'),\n","    'plots_waveform': os.path.join(root_dir, 'results/plots/waveform'),\n","    'plots_spectrograms': os.path.join(root_dir, 'results/plots/spectrograms'),\n","    'plots_xai': os.path.join(root_dir, 'results/plots/xai'),\n","    'plots_Grad-CAM': os.path.join(root_dir, 'results/plots/xai/Grad-CAM'),\n","}\n","\n","# labels and number of splits\n","labels = ['gender','digit']\n","splits = 5\n","\n","# append the directory to the python path using sys in order to make the seperate py files importable\n","sys.path.append(root_dir)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7fwR0VaD96nP"},"source":["## Utils"]},{"cell_type":"code","metadata":{"id":"VZG4mLNz8xs0","executionInfo":{"status":"ok","timestamp":1631178221788,"user_tz":-120,"elapsed":904,"user":{"displayName":"Philipp Rössler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08136704935029710025"}}},"source":["########## 1. function to write log about the events\n","def write_log(message):\n","    logging.basicConfig(level = logging.INFO, filename=os.path.join(root_dir,'events.log'), filemode='a', format='%(asctime)s - %(message)s')\n","    logging.info(message)\n","    print(message) \n","\n","\n","########## 2. function to create a directory\n","def create_directory(directory_path):\n","    if os.path.isdir(directory_path) == False:\n","        os.mkdir(directory_path)\n","        write_log('Created folder: '+directory_path)\n","    #else:\n","        #writeLog('Folder already exists: '+directory_path)\n","\n","########## 3. function to calculate time difference between two timepoints from package 'time' and returns the duration in format HH:MM:SS as String\n","def get_duration(start_time,end_time):\n","    duration = round(end_time-start_time)\n","    if duration < 0:\n","        duration*=-1\n","    h=math.floor(duration/3600)\n","    r=duration%3600\n","    m=math.floor(r/60)\n","    r=r%60\n","    s=round(r)\n","    return(str(h).zfill(2)+':'+str(m).zfill(2)+':'+str(s).zfill(2))\n","\n","########### 4. function to read spectrograms/labels and return np.arrays ready for training/evaluation/xai methods\n","def read_spectrograms_hdf5(label,split_index,split_type,resize_factor=1,reshape=False,img_width=227, img_height=227, img_num_channels=1):\n","  write_log('Started reading '+str(split_type)+' data ...')\n","  start_time = time.time()\n","  if label == 'gender':\n","    label_index = 1\n","  else:\n","    label_index = 0\n","  # read txt with current split paths\n","  path_to_split_paths = os.path.join(paths['splits'],'AlexNet_'+str(label)+'_'+str(split_index)+'_'+str(split_type)+'.txt')\n","  text_file = open(path_to_split_paths, 'r')\n","  split_paths = text_file.read().split('\\n')\n","  text_file.close()\n","  # if there are empty lines at the end of the txt file there will be an empty list element for each empty line\n","  # removing empty lines/list elements\n","  while split_paths[len(split_paths)-1] == '':\n","    split_paths.pop(len(split_paths)-1)\n","  # read hdf5 files of the current split and split_type and store it as np.array (spectrograms as x and labels as y)\n","  index = 0\n","  x = np.zeros(((len(split_paths),227,227))) # create target array for spectrograms\n","  y = np.zeros(len(split_paths)) # create target array for labels\n","  for cur_path in split_paths: # iterate the files\n","    #read current file\n","    f = h5py.File(cur_path, 'r')\n","    x_cur = f['data'][...]\n","    y_cur = f['label'][...]\n","    f.close() \n","    #extract relevant data of current file\n","    x_cur = x_cur[0][0]\n","    y_cur = y_cur[0][label_index]    \n","    #append current data to x and y\n","    x[index] = x_cur\n","    y[index] = y_cur\n","    # increase index by 1\n","    index +=1\n","  x = x/resize_factor\n","  if reshape:\n","    x = x.reshape((len(x), img_width, img_height, img_num_channels))\n","  write_log('Finished reading '+str(split_type)+' data in '+get_duration(start_time,time.time()))\n","  return x,y\n","\n","# read txt with current testsplit paths (txt contains paths to spectrograms)\n","def get_split_paths(path_to_split_paths):\n","  text_file = open(path_to_split_paths, 'r')\n","  split_paths = text_file.read().split('\\n')\n","  text_file.close()\n","  # if there are empty lines at the end of the txt file there will be an empty list element for each empty line\n","  # removing empty lines/list elements\n","  while split_paths[len(split_paths)-1] == '':\n","    split_paths.pop(len(split_paths)-1)\n","  return split_paths\n","\n","# function to read a single hdf5 spectrogram\n","def read_single_spectrogram_hdf5(filepath):\n","  f = h5py.File(filepath, 'r')\n","  x = f['data'][...]\n","  y = f['label'][...]\n","  f.close()\n","  return x,y\n","\n","#create directories for the results\n","for path in paths:\n","  if 'result' in paths[path]:\n","    create_directory(paths[path])"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DUMQgazI5py_"},"source":["# Waveform and spectrogram plots"]},{"cell_type":"code","metadata":{"id":"cHPrMhsQ5tkf","executionInfo":{"status":"ok","timestamp":1631180725023,"user_tz":-120,"elapsed":207,"user":{"displayName":"Philipp Rössler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08136704935029710025"}}},"source":["# function creates a waveform plot for a single .wav file\n","# src is the path to the .wav file\n","# dst is the path were the plot is saved to\n","# optional the y-axis can be scaled between -1 and 1 (default True)\n","# optional the plot can be shown (default False)\n","def create_waveform_plot(src,dst,scale=True,show=False):\n","  if os.path.isfile(dst):\n","    return False\n","  create_directory(os.path.join(paths['plots_waveform'],dst.split('/')[-2])) #create the subfolder with participant number, eg. 01\n","  fs, data = wavf.read(src)\n","  if scale:\n","    data = minmax_scale(data,feature_range=(-1,1),axis=0,copy=True) # optional: scales the y-axis between -1 and 1\n","  duration = len(data)/fs #duration of the file\n","  time_values = np.arange(0,duration,1/fs) #time vector\n","  # sometimes time and data dont have the same length which causes an error: fix by adjusting the length\n","  if len(time_values) != len(data):\n","    if len(time_values)>len(data):\n","      time_values = time_values[0:len(data)]\n","    else:\n","      data = data[0:len(time_values)]\n","  plt.plot(time_values,data)\n","  plt.xlabel('Time [s]')\n","  plt.ylabel('Amplitude')\n","  plt.savefig(dst)\n","  if show:\n","    plt.show()\n","  plt.close()\n","  return True\n","\n","# function creates a spectrogram plot for a single .hdf5 file - analog to the function for waveform files\n","def create_spectrogram_plot(cur_spectrogram_data,dst,show=False):\n","  if os.path.isfile(dst):\n","    return False\n","  create_directory(os.path.join(paths['plots_spectrograms'],dst.split('/')[-2])) #create the subfolder with participant number, eg. 01\n","  # reshape data, create spectrogram image, save as png\n","  data = cur_spectrogram_data\n","  data = np.squeeze(data) # alternatively use: data = data[0,0]\n","  data = data.reshape(227,227,1)\n","  img = array_to_img(data)\n","  img = ImageOps.flip(img) # the picture is otherwise upside down\n","  img.save(dst)\n","  if show:\n","    display(img)\n","  return True"],"execution_count":54,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7jW8TMdXgFjJ"},"source":["# Grad-CAM\n","The Code was reimplemented from the following source:\n","https://keras.io/examples/vision/grad_cam/"]},{"cell_type":"markdown","metadata":{"id":"EfmgsPRq9hKl"},"source":["## Functions to create a single heatmap"]},{"cell_type":"code","metadata":{"id":"cs2bbbnZgM5D","executionInfo":{"status":"ok","timestamp":1631178226183,"user_tz":-120,"elapsed":248,"user":{"displayName":"Philipp Rössler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08136704935029710025"}}},"source":["# Note: the following function is from https://keras.io/examples/vision/grad_cam/\n","def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n","    # First, we create a model that maps the input image to the activations\n","    # of the last conv layer as well as the output predictions\n","    grad_model = tf.keras.models.Model(\n","        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n","    )\n","    # Then, we compute the gradient of the top predicted class for our input image\n","    # with respect to the activations of the last conv layer\n","    with tf.GradientTape() as tape:\n","        last_conv_layer_output, preds = grad_model(img_array)\n","        if pred_index is None:\n","            pred_index = tf.argmax(preds[0])\n","        class_channel = preds[:, pred_index]\n","    # This is the gradient of the output neuron (top predicted or chosen)\n","    # with regard to the output feature map of the last conv layer\n","    grads = tape.gradient(class_channel, last_conv_layer_output)\n","    # This is a vector where each entry is the mean intensity of the gradient\n","    # over a specific feature map channel\n","    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","    # We multiply each channel in the feature map array\n","    # by \"how important this channel is\" with regard to the top predicted class\n","    # then sum all the channels to obtain the heatmap class activation\n","    last_conv_layer_output = last_conv_layer_output[0]\n","    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n","    heatmap = tf.squeeze(heatmap)\n","    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n","    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n","    return heatmap.numpy()\n","# Note: the following function is from https://keras.io/examples/vision/grad_cam/\n","def save_and_display_gradcam(img, heatmap, dst, alpha=0.4, show=False):\n","    # Rescale heatmap to a range 0-255\n","    heatmap = np.uint8(255 * heatmap)\n","    # Use jet colormap to colorize heatmap\n","    jet = cm.get_cmap(\"jet\")\n","    # Use RGB values of the colormap\n","    jet_colors = jet(np.arange(256))[:, :3]\n","    jet_heatmap = jet_colors[heatmap]\n","    # Create an image with RGB colorized heatmap\n","    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n","    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n","    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n","    # Superimpose the heatmap on original image\n","    superimposed_img = jet_heatmap * alpha + img\n","    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n","    superimposed_img = ImageOps.flip(superimposed_img) # the picture is otherwise upside down\n","    # Save the superimposed image\n","    superimposed_img.save(dst)\n","    # Display Grad CAM\n","    if show:\n","      display(superimposed_img)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yFl1oGNxdAkW"},"source":["## Prepare spectrograms and call Grad-CAM functions"]},{"cell_type":"code","metadata":{"id":"28m9vgEB_8nM","executionInfo":{"status":"ok","timestamp":1631180703755,"user_tz":-120,"elapsed":206,"user":{"displayName":"Philipp Rössler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08136704935029710025"}}},"source":["# function transforms data into the correct shape and calls the Grad-CAM functions above\n","def create_single_grad_cam(spectrogram_data,dst,model,show=False):\n","  if os.path.isfile(dst):\n","    return False\n","  # TODO mkdirs from dst\n","  create_directory(os.path.join(paths['plots_Grad-CAM'],dst.split('/')[-3])) #create the subfolder with label and split (one is needed for each model), eg. label_gender_split_1\n","  create_directory(os.path.join(paths['plots_Grad-CAM'],dst.split('/')[-3],dst.split('/')[-2])) #create the subfolder with participant number, eg. 01\n","  # reshape image to grayscale\n","  img = spectrogram_data.reshape(227,227,1)\n","  # reshape data for model\n","  x_cur = spectrogram_data/255\n","  x_cur = x_cur.reshape(1,227,227,1)\n","  # define last convolutional layer\n","  last_conv_layer_name = 'conv2d_4'\n","  # Remove last layer's softmax\n","  model.layers[-1].activation = None\n","  # Generate class activation heatmap\n","  heatmap = make_gradcam_heatmap(x_cur, model, last_conv_layer_name)\n","  # Merge heatmap with original image and save result\n","  save_and_display_gradcam(img, heatmap,dst,show=show)\n","  return True"],"execution_count":53,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nB8uFJrPKFoX"},"source":["# Input handlers"]},{"cell_type":"markdown","metadata":{"id":"rT2bPoZeeBKo"},"source":["## For several spectrograms"]},{"cell_type":"code","metadata":{"id":"fctMQTZkgM-T","executionInfo":{"status":"ok","timestamp":1631185024565,"user_tz":-120,"elapsed":855,"user":{"displayName":"Philipp Rössler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08136704935029710025"}}},"source":["def check_inputs(selected_outputs,selected_labels,selected_splits,selected_mode,selected_nb_examples,selected_scale,selected_show):\n","  # set valid inputs\n","  valid_outputs = ['waveform','spectrograms','Grad-CAM']\n","  valid_labels = ['gender','digit']\n","  valid_splits = [0,1,2,3,4]\n","  valid_mode = ['examples','all','single']\n","  valid_nb_examples = list(range(1, 6)) # second value is not valid, example: range(1,3) --> [1,2]\n","  valid_scale = [False,True]\n","  valid_show = [False,True]\n","  # check validity of the selected inputs\n","  for selected_output in selected_outputs:\n","    if selected_output not in valid_outputs:\n","      write_log('Interrupted due to incorrect input parameters in selected outputs!')\n","      return False\n","  for selected_label in selected_labels:\n","    if selected_label not in valid_labels:\n","      write_log('Interrupted due to incorrect input parameters in selected labels!')\n","      return False\n","  for selected_split in selected_splits:\n","    if selected_split not in valid_splits:\n","      write_log('Interrupted due to incorrect input parameters in selected splits!')\n","      return False\n","  if selected_splits == [4] and selected_labels == ['gender']:\n","    write_log('Interrupted due to incorrect input parameters: Model gender 4 does not exist!')\n","    return False\n","  if selected_mode[0] not in valid_mode or len(selected_mode)>1:\n","    write_log('Interrupted due to incorrect input parameters in selected mode!')\n","    return False\n","  if selected_nb_examples not in valid_nb_examples:\n","    write_log('Interrupted due to incorrect input parameters in selected nb examples!')\n","    return False\n","  if selected_scale not in valid_scale:\n","    write_log('Interrupted due to incorrect input parameters in selected scale!')\n","    return False\n","  if selected_show not in valid_show:\n","    write_log('Interrupted due to incorrect input parameters in selected show!')\n","    return False\n","\n","def create_outputs(selected_outputs,selected_labels,selected_splits,selected_mode='single',selected_nb_examples=3,selected_scale=True,selected_show=False):\n","  write_log('Started creating outputs ...')\n","  # handle wrong inputs\n","  valid_inputs = check_inputs(selected_outputs,selected_labels,selected_splits,selected_mode,selected_nb_examples,selected_scale,selected_show)\n","  if valid_inputs == False:\n","    return\n","  # set output types: needed to find correct path from paths variable\n","  output_types = ['plots_waveform','plots_spectrograms','plots_Grad-CAM']\n","  # read meta to get gender label later\n","  metaData = json.load(open(paths['meta']))\n","  # iterate existing models\n","  for model_name in os.listdir(paths['models']):\n","    # load model\n","    model = load_model(os.path.join(paths['models'],model_name))\n","    net,label,split_index = model_name.rstrip(\".h5\").split(\"/\")[-1].split(\"_\")\n","    write_log('Current Model: '+label+'_'+str(split_index))\n","    # skip current model, if label or split was not selected\n","    if label not in selected_labels or int(split_index) not in selected_splits:\n","      write_log('Model not selected!')\n","      continue\n","    # set path to txt file which contains the spectrogram paths of the current test split\n","    path_to_split_paths = os.path.join(paths['splits'],net+'_'+str(label)+'_'+str(split_index)+'_test'+'.txt')\n","    # read txt\n","    split_paths = get_split_paths(path_to_split_paths)\n","    # set counters for breaks\n","    file_counter = 0\n","    example_counter_male = [0,0,0,0,0,0,0,0,0,0]\n","    example_counter_female = [0,0,0,0,0,0,0,0,0,0]\n","    # set counters to track how many outputs were generated/existed\n","    created_counter ={'waveform': 0, 'spectrograms': 0, 'Grad-CAM': 0}\n","    existed_counter ={'waveform': 0, 'spectrograms': 0, 'Grad-CAM': 0}\n","    # iterate files in testsplit  \n","    for filepath in split_paths:\n","      # if single mode is selected skip after the first file\n","      if file_counter >0:\n","        break\n","      # infer sample info from name\n","      net, dig, vp, rep = filepath[:len(filepath)-5].split('/')[-1].split('_') # filepath.rstrip(\".hdf5\").split(\"/\")[-1].split(\"_\") --> cutting of reperition 5 for example\n","      # get gender\n","      gender = 0 if metaData[vp][\"gender\"] == \"male\" else 1 \n","      # if example mode is selected skip if nb_examples is reached\n","      if gender == 0:\n","        if example_counter_male[int(dig)] == int(selected_nb_examples): # continue if enough examples are created for the current digit\n","          continue\n","      else:\n","        if example_counter_female[int(dig)] == int(selected_nb_examples): # continue if enough examples are created for the current digit\n","          continue \n","      # set saving paths\n","      dst = {}\n","      for output_type in output_types: # for XAI methods there are different output plots for each model which makes an additional folder structure necessary\n","        if output_type in ['plots_waveform','plots_spectrograms']:\n","          additional_folder = '' # no additional folder for waveform and spectrograms\n","        else:\n","          additional_folder = 'label_'+str(label)+'_split_'+str(split_index) # additional folder (for each model) for XAI methods\n","        dst[output_type] = os.path.join(paths[output_type],additional_folder,str(vp),str(gender)+'_'+str(dig)+'_'+str(vp)+'_'+str(rep)+'.png') # set path\n","      # set waveform source path\n","      src_waveform = os.path.join(paths['data'],str(vp),str(dig)+'_'+str(vp)+'_'+str(rep)+'.wav')\n","      # read spectrogram from hdf5 file\n","      cur_spectrogram_data,_ = read_single_spectrogram_hdf5(filepath)\n","      # call functions to create outputs\n","      if 'waveform' in selected_outputs:\n","        count = create_waveform_plot(src_waveform,dst['plots_waveform'],scale=selected_scale,show=selected_show)\n","        if count == True: created_counter['waveform'] += 1\n","        elif count == False: existed_counter['waveform'] +=1\n","      if 'spectrograms' in selected_outputs:\n","        count = create_spectrogram_plot(cur_spectrogram_data,dst['plots_spectrograms'],show=selected_show)\n","        if count == True: created_counter['spectrograms'] += 1\n","        elif count == False: existed_counter['spectrograms'] +=1        \n","      if 'Grad-CAM' in selected_outputs:\n","        count = create_single_grad_cam(cur_spectrogram_data,dst['plots_Grad-CAM'],model,show=selected_show)\n","        if count == True: created_counter['Grad-CAM'] += 1\n","        elif count == False: existed_counter['Grad-CAM'] +=1\n","      if selected_mode == ['single']:\n","        file_counter +=1\n","      if selected_mode == ['examples']:\n","        if gender == 0:\n","          example_counter_male[int(dig)] +=1\n","        else:\n","          example_counter_female[int(dig)] +=1\n","    if 'waveform' in selected_outputs:\n","      write_log('Waveform: created '+str(created_counter['waveform'])+', existed '+str(existed_counter['waveform']))\n","    if 'spectrograms' in selected_outputs:\n","      write_log('Spectrograms: created '+str(created_counter['spectrograms'])+', existed '+str(existed_counter['spectrograms']))\n","    if 'Grad-CAM' in selected_outputs:\n","      write_log('Grad-CAM: created '+str(created_counter['Grad-CAM'])+', existed '+str(existed_counter['Grad-CAM']))"],"execution_count":96,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xz3vEhz0eIfk"},"source":["## For specific spectrogram"]},{"cell_type":"code","metadata":{"id":"qgV1hItRforH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kQD3hAjMeStI"},"source":["# Set outputs and run script"]},{"cell_type":"markdown","metadata":{"id":"XFuQaNU4J6Zk"},"source":["## Set outputs for several spectrograms"]},{"cell_type":"code","metadata":{"id":"jJtDeSn2gNA2","executionInfo":{"status":"ok","timestamp":1631185198280,"user_tz":-120,"elapsed":225,"user":{"displayName":"Philipp Rössler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08136704935029710025"}}},"source":["selected_outputs = ['waveform','spectrograms','Grad-CAM'] # Note: don't use single strings, example: 'waveform' --> won't work, ['waveform'] --> works\n","selected_labels = ['gender','digit'] # see Note for selected_outputs\n","selected_splits = [0,1,2,3,4] # see Note for selected_outputs\n","selected_mode = ['examples'] # options: 'examples' 'all' 'single' (default: 'examples'), see Note for selected_outputs\n","selected_nb_examples = 1 # number of examples for each digit of each participant (Allowed range: 1-5, default: 3)\n","selected_scale = True # only for waveform plots: optionally the y-axis can be scaled between -1 and 1 (default: True)\n","selected_show = False # optionally the plot can be shown (default: False)"],"execution_count":99,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8oHGFj6pKSTf"},"source":["## Run script for several spectrograms"]},{"cell_type":"code","metadata":{"id":"e6GBxauRgNEU"},"source":["create_outputs(selected_outputs,selected_labels,selected_splits,selected_mode,selected_nb_examples,selected_scale,selected_show)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CdCtNXcSe5mQ"},"source":["## Set outputs for a specific spectrogram"]},{"cell_type":"code","metadata":{"id":"QGdkIDpvtR-u","executionInfo":{"status":"ok","timestamp":1631180179691,"user_tz":-120,"elapsed":227,"user":{"displayName":"Philipp Rössler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08136704935029710025"}}},"source":[""],"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jqip1FRre94T"},"source":["## Run script for a specific spectrogram"]},{"cell_type":"code","metadata":{"id":"JjhMk_uzVmye","executionInfo":{"status":"ok","timestamp":1631182101225,"user_tz":-120,"elapsed":220,"user":{"displayName":"Philipp Rössler","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08136704935029710025"}}},"source":[""],"execution_count":65,"outputs":[]}]}